{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.读取初始数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000000\n",
      "2000000\n",
      "3000000\n",
      "4000000\n",
      "5000000\n",
      "6000000\n",
      "7000000\n",
      "8000000\n",
      "9000000\n",
      "10000000\n",
      "11000000\n",
      "12000000\n",
      "13000000\n",
      "14000000\n",
      "15000000\n",
      "16000000\n",
      "17000000\n",
      "18000000\n",
      "19000000\n",
      "20000000\n",
      "21000000\n",
      "22000000\n",
      "23000000\n",
      "24000000\n",
      "25000000\n",
      "26000000\n",
      "27000000\n",
      "28000000\n",
      "29000000\n",
      "30000000\n",
      "31000000\n",
      "32000000\n",
      "33000000\n",
      "34000000\n",
      "35000000\n",
      "36000000\n",
      "37000000\n",
      "38000000\n",
      "39000000\n",
      "40000000\n",
      "41000000\n",
      "42000000\n",
      "43000000\n",
      "44000000\n",
      "45000000\n",
      "46000000\n",
      "47000000\n",
      "48000000\n",
      "49000000\n",
      "50000000\n",
      "51000000\n",
      "52000000\n",
      "53000000\n",
      "54000000\n",
      "55000000\n",
      "56000000\n",
      "57000000\n",
      "58000000\n",
      "59000000\n",
      "60000000\n",
      "61000000\n",
      "62000000\n",
      "63000000\n",
      "64000000\n",
      "65000000\n",
      "65001293\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['!=', 'BaiduTAG', '语言术语']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "count = 0\n",
    "with open('baike_triples.txt', 'r', encoding='utf8') as f:\n",
    "    d = f.readline()\n",
    "    while d:\n",
    "        if count%3000000==0:\n",
    "            print(count)\n",
    "        count+=1\n",
    "        data.append(d.strip().split('\\t'))\n",
    "        d = f.readline()\n",
    "print(len(data))\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.保留元素全为中文的三元组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19715348"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_chinese = re.compile('^[\\u4e00-\\u9fa5]*$')\n",
    "new_data = []\n",
    "for triple in data:\n",
    "    if bool(re.search(all_chinese, triple[0])):\n",
    "        if bool(re.search(all_chinese, triple[1])):\n",
    "            if bool(re.search(all_chinese, triple[2])):\n",
    "                new_data.append(triple)\n",
    "len(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.实体字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3000000\n",
      "6000000\n",
      "9000000\n",
      "12000000\n",
      "15000000\n",
      "18000000\n"
     ]
    }
   ],
   "source": [
    "entities = {}\n",
    "count = 0\n",
    "for can in new_data:\n",
    "    if count %3000000==0:\n",
    "        print(count)\n",
    "    count+=1\n",
    "    entities[can[0]] = entities.get(can[0], {})\n",
    "    entities[can[0]][can[1]] = can[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('processed'):\n",
    "    os.mkdir('processed')\n",
    "with open('processed/entities.pkl', 'wb') as f:\n",
    "    pickle.dump(entities, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e_set = set(list(entities.keys()))\n",
    "with open('dict.txt', 'w', encoding='utf8') as f:\n",
    "    for e in e_set:\n",
    "        f.write(e+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.获取句子集合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4003897"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = []\n",
    "for can in data:\n",
    "    if can[1]=='BaiduCARD':\n",
    "        sentences.append(can[2])\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'！文档类型，一个文档类型标记是一种<a>标准通用标记语言</a>的文档类型声明，它的目的是要告诉<a>标准通用标记语言</a>解析器，它应该使用什么样的文档类型定义（<a>DTD</a>）来解析<a>文档</a>。'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13963183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sentences = []\n",
    "for i in range(len(sentences)):\n",
    "    tp = sentences[i]\n",
    "    sen = re.sub(' +', ' ', tp)\n",
    "    sen = re.sub('[^\\u4e00-\\u9fa5,\\?\\!，。？：:！、；\\(\\)（） ]', '', sen)\n",
    "    sen = re.split('[\\?\\!。？！]', sen)\n",
    "    for s in sen:\n",
    "        if s!='':\n",
    "            new_sentences.append(s)\n",
    "print(len(new_sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.句子存为100个文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103798\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir('processed/sentences'):\n",
    "    os.mkdir('processed/sentences')\n",
    "\n",
    "begin = 0\n",
    "count = math.ceil(len(new_sentences)*1.0/100)\n",
    "print(count)\n",
    "end = min(begin+count, len(new_sentences))\n",
    "for i in range(100):\n",
    "    with open('processed/sentences/sen'+str(i), 'wb') as f:\n",
    "        pickle.dump(new_sentences[begin:end], f)\n",
    "    begin = end\n",
    "    end = min(begin+count, len(new_sentences))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
