{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.读取初始数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "count = 0\n",
    "with open('baike_triples.txt', 'r', encoding='utf8') as f:\n",
    "    d = f.readline()\n",
    "    while d:\n",
    "        if count%3000000==0:\n",
    "            print(count)\n",
    "        count+=1\n",
    "        data.append(d.strip().split('\\t'))\n",
    "        d = f.readline()\n",
    "print(len(data))\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.保留元素全为中文的三元组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_chinese = re.compile('^[\\u4e00-\\u9fa5]*$')\n",
    "new_data = []\n",
    "for triple in data:\n",
    "    if bool(re.search(all_chinese, triple[0])):\n",
    "        if bool(re.search(all_chinese, triple[1])):\n",
    "            if bool(re.search(all_chinese, triple[2])):\n",
    "                new_data.append(triple)\n",
    "len(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.实体字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "entities = {}\n",
    "count = 0\n",
    "for can in new_data:\n",
    "    if count %3000000==0:\n",
    "        print(count)\n",
    "    count+=1\n",
    "    entities[can[0]] = entities.get(can[0], {})\n",
    "    entities[can[0]][can[1]] = can[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('processed'):\n",
    "    os.mkdir('processed')\n",
    "with open('processed/entities.pkl', 'wb') as f:\n",
    "    pickle.dump(entities, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_set = set(list(entities.keys()))\n",
    "with open('dict.txt', 'w', encoding='utf8') as f:\n",
    "    for e in e_set:\n",
    "        f.write(e+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.获取句子集合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for can in data:\n",
    "    if can[1]=='BaiduCARD':\n",
    "        sentences.append(can[2])\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sentences = []\n",
    "for i in range(len(sentences)):\n",
    "    tp = sentences[i]\n",
    "    sen = re.sub(' +', ' ', tp)\n",
    "    sen = re.sub('[^\\u4e00-\\u9fa5,\\?\\!，。？：:！、；\\(\\)（） ]', '', sen)\n",
    "    sen = re.split('[\\?\\!。？！]', sen)\n",
    "    for s in sen:\n",
    "        if s!='':\n",
    "            new_sentences.append(s)\n",
    "print(len(new_sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.句子存为100个文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('processed/sentences'):\n",
    "    os.mkdir('processed/sentences')\n",
    "\n",
    "begin = 0\n",
    "count = math.ceil(len(new_sentences)*1.0/100)\n",
    "print(count)\n",
    "end = min(begin+count, len(new_sentences))\n",
    "for i in range(100):\n",
    "    with open('processed/sentences/sen'+str(i), 'wb') as f:\n",
    "        pickle.dump(new_sentences[begin:end], f)\n",
    "    begin = end\n",
    "    end = min(begin+count, len(new_sentences))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
